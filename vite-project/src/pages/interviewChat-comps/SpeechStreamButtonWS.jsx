// src/components/interviewChat-comps/SpeechStreamButtonWS.jsx
import { useEffect, useRef, useState } from "react";
import styles from "../../styles/interviewChat.module.css";

const TARGET_SR = 16000;

// ë‹¤ìš´ìƒ˜í”Œë§(F32 â†’ F32 @16k)
const downsample = (float32, inRate, outRate) => {
  if (inRate === outRate) return float32;
  const ratio = inRate / outRate;
  const newLen = Math.floor(float32.length / ratio);
  const out = new Float32Array(newLen);
  let pos = 0;
  for (let i = 0; i < newLen; i++) {
    const nextPos = (i + 1) * ratio;
    let sum = 0, count = 0;
    for (; pos < nextPos && pos < float32.length; pos++) {
      sum += float32[Math.floor(pos)];
      count++;
    }
    out[i] = sum / (count || 1);
  }
  return out;
};

// F32 â†’ S16LE
const floatTo16 = (float32) => {
  const out = new Int16Array(float32.length);
  for (let i = 0; i < float32.length; i++) {
    let s = Math.max(-1, Math.min(1, float32[i]));
    out[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
  }
  return out;
};

const SpeechStreamButtonWS = ({ wsRef, onUserText }) => {
  const mediaRef = useRef(null);
  const procRef = useRef(null);
  const audioCtxRef = useRef(null);
  const [isRec, setIsRec] = useState(false);
  const [hint, setHint] = useState("");

  const start = async () => {
    if (isRec) return;
    try {
      // ë°œí™” ì‹œì‘ ì•Œë¦¼(ì„œë²„ê°€ ì´ ì‹œì ë¶€í„° STT ë²„í¼ë§)
      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({ type: "UTTERANCE_START", format: "pcm_s16le" }));
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRef.current = stream;

      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      audioCtxRef.current = audioCtx;
      const source = audioCtx.createMediaStreamSource(stream);

      const proc = audioCtx.createScriptProcessor(4096, 1, 1);
      proc.onaudioprocess = (ev) => {
        const input = ev.inputBuffer.getChannelData(0);
        const ds = downsample(input, audioCtx.sampleRate, TARGET_SR);
        const pcm16 = floatTo16(ds);
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
          wsRef.current.send(pcm16.buffer); // ğŸ”¹ ê°™ì€ WSë¡œ ë°”ì´ë„ˆë¦¬ ì „ì†¡
        }
      };
      procRef.current = proc;
      source.connect(proc);
      proc.connect(audioCtx.destination); // or ì œê±°

      setIsRec(true);
      setHint("ë…¹ìŒ ì¤‘â€¦");
    } catch (e) {
      setHint(`ë§ˆì´í¬ ì˜¤ë¥˜: ${e.message}`);
      stop();
    }
  };

  const stop = () => {
    try { procRef.current?.disconnect(); } catch {}
    procRef.current = null;

    try { audioCtxRef.current?.close(); } catch {}
    audioCtxRef.current = null;

    try { mediaRef.current?.getTracks?.().forEach(t => t.stop()); } catch {}
    mediaRef.current = null;

    setIsRec(false);
    setHint("");

    // ë°œí™” ì¢…ë£Œ ì•Œë¦¼ (ì„œë²„ê°€ ì—¬ê¸°ì„œ STT ìˆ˜í–‰ â†’ ì§ˆë¬¸/ì˜¤ë””ì˜¤ ì‘ë‹µ í‘¸ì‹œ)
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: "UTTERANCE_END" }));
    }

    // (ì„ íƒ) ì‚¬ìš©ìê°€ ë°©ê¸ˆ ë§í•œ í…ìŠ¤íŠ¸ë¥¼ UIì— ì„ ë°˜ì˜í•˜ê³  ì‹¶ë‹¤ë©´
    // onUserText?.("(ì‚¬ìš©ì ë°œí™” ì „ì†¡ë¨)");
  };

  useEffect(() => () => stop(), []);

  return (
    <div className={styles.inputRow}>
      <button
        className={`${styles.micBtn} ${isRec ? styles.active : ""}`}
        onClick={isRec ? stop : start}
        aria-pressed={isRec}
        title={isRec ? "ë…¹ìŒ ì¢…ë£Œ" : "ë…¹ìŒ ì‹œì‘"}
      >
        ğŸ¤
      </button>

      <div className={styles.sttPreview}>
        {isRec
          ? <span className={styles.interimText}>{hint || "ë…¹ìŒ ì¤‘â€¦"}</span>
          : <span className={styles.sttTextMuted}>ë§ˆì´í¬ ëŒ€ê¸°</span>}
      </div>
    </div>
  );
};

export default SpeechStreamButtonWS;
